The file config.py code is this:
"""
Configuration and constants for the problem generation framework.
"""

from dataclasses import dataclass
from typing import Dict
import os


# @dataclass
# class TimeDifficultyTier:
#     """Definition of a difficulty tier based on solving time."""
#     name: str
#     min_time: float      # seconds
#     max_time: float      # seconds
#     target_time: float   # seconds (for reporting)
#     max_rejects: float   # Don't use config if it takes longer than this
#
#
# # Existing plan-length tiers
# DIFFICULTY_TIERS = {
#     'small': DifficultyTier(
#         name='small',
#         min_length=15,
#         max_length=17,
#         target_length=16
#     ),
#     'medium': DifficultyTier(
#         name='medium',
#         min_length=25,
#         max_length=30,
#         target_length=27
#     ),
#     'large': DifficultyTier(
#         name='large',
#         min_length=500,
#         max_length=1000,
#         target_length=858
#     ),
# }
#
# # NEW: Time-based difficulty tiers
# TIME_DIFFICULTY_TIERS = {
#     'small': TimeDifficultyTier(
#         name='small',
#         min_time=30,          # 30 seconds
#         max_time=90,          # 1.5 minutes
#         target_time=60,
#         max_rejects=120       # Stop trying config if > 2 min
#     ),
#     'medium': TimeDifficultyTier(
#         name='medium',
#         min_time=180,         # 3 minutes
#         max_time=240,         # 4 minutes
#         target_time=210,
#         max_rejects=270       # 4.5 minutes (your threshold)
#     ),
#     'large': TimeDifficultyTier(
#         name='large',
#         min_time=600,         # 10 minutes
#         max_time=900,         # 15 minutes
#         target_time=750,
#         max_rejects=1200      # 20 minutes
#     ),
# }
#
# # Baseline planner configuration
# BASELINE_PLANNER_CONFIG = {
#     'planner': 'downward',
#     'search': 'astar(lmcut())',
#     'timeout': 240,  # 10 minutes in seconds
# }
#
# # Generation parameters
# MAX_BLOCKS = 14
# MIN_BLOCKS = 10
#
# # Calibration parameters (NEW)
# CALIBRATION_CONFIG = {
#     'initial_samples_per_config': 20,  # Try each config twice during calibration
#     'min_configs_to_find': 20,          # Find at least 3 working configurations
#     'block_range': range(11, 13),        # Try 4-7 blocks
#     'plan_length_step': 500,             # Step size for plan length sampling
# }


@dataclass
class DifficultyTier:
    """Definition of a difficulty tier based on plan length."""
    name: str
    min_length: int
    max_length: int
    target_length: int


# Difficulty tier definitions (Requirement #16)
DIFFICULTY_TIERS = {
    'small': DifficultyTier(
        name='small',
        min_length=15,
        max_length=17,
        target_length=16
    ),
    'medium': DifficultyTier(
        name='medium',
        min_length=25,
        max_length=30,
        target_length=27
    ),
    'large': DifficultyTier(
        name='large',
        min_length=50,
        max_length=500,
        target_length=151
    ),
}



# Baseline planner configuration (Requirement #12)
BASELINE_PLANNER_CONFIG = {
    'planner': 'downward',
    'search': 'astar(lmcut())',
    'timeout': 260,  # 10 minutes in seconds
}

# Generation parameters
MAX_BLOCKS = 10
MIN_BLOCKS = 3

# Output directories
OUTPUT_DIR = 'generated_problems'
DOMAIN_DIR = os.path.join(OUTPUT_DIR, 'domains')
PROBLEMS_DIR = os.path.join(OUTPUT_DIR, 'problems')
METADATA_DIR = os.path.join(OUTPUT_DIR, 'metadata')

# Directories to create
REQUIRED_DIRS = [OUTPUT_DIR, DOMAIN_DIR, PROBLEMS_DIR, METADATA_DIR]


def ensure_output_dirs():
    """Create required output directories if they don't exist."""
    for dir_path in REQUIRED_DIRS:
        os.makedirs(dir_path, exist_ok=True)



--------------------------------------------------------------------------------

The file state.py code is this:
"""
State representation for Blocksworld and state validation.

A valid Blocksworld state consists of:
- on_table: set of blocks on the table
- on: dict mapping block -> block (stacking relations)
- clear: set of blocks with nothing on top (and not held)
- arm_empty: boolean
- holding: block or None
"""

from typing import Set, Dict, Optional, Tuple
from dataclasses import dataclass, field


@dataclass
class BlocksWorldState:
    """Represents a Blocksworld state."""
    blocks: Set[str]
    on_table: Set[str] = field(default_factory=set)
    on: Dict[str, str] = field(default_factory=dict)  # block -> block it's on
    clear: Set[str] = field(default_factory=set)
    arm_empty: bool = True
    holding: Optional[str] = None

    def copy(self) -> 'BlocksWorldState':
        """Create a deep copy of the state."""
        return BlocksWorldState(
            blocks=self.blocks.copy(),
            on_table=self.on_table.copy(),
            on=self.on.copy(),
            clear=self.clear.copy(),
            arm_empty=self.arm_empty,
            holding=self.holding
        )

    def is_valid(self) -> Tuple[bool, Optional[str]]:
        """
        Validate state against Blocksworld constraints.

        Returns:
            (is_valid, error_message)
        """
        # Check: Each block must be exactly one of: on_table, on another block, or held
        for block in self.blocks:
            on_table = block in self.on_table
            on_another = block in self.on
            held = block == self.holding

            count = sum([on_table, on_another, held])
            if count != 1:
                return False, f"Block {block} is in {count} positions (should be exactly 1)"

        # Check: Arm state consistency
        if self.arm_empty and self.holding is not None:
            return False, "Arm cannot be both empty and holding a block"
        if not self.arm_empty and self.holding is None:
            return False, "Arm is not empty but not holding any block"
        if self.holding is not None and self.holding not in self.blocks:
            return False, f"Arm is holding non-existent block {self.holding}"

        # Check: on relations point to existing blocks
        for on_block, under_block in self.on.items():
            if under_block not in self.blocks:
                return False, f"Block {on_block} claims to be on non-existent block {under_block}"
            if under_block == on_block:
                return False, f"Block {on_block} cannot be on itself"

        # Check: Clear predicate validity
        # FIX: A block is clear if it's NOT held AND nothing is on top of it
        for block in self.blocks:
            is_clear = (self.holding != block and block not in self.on.values())
            should_be_clear = block in self.clear
            if is_clear != should_be_clear:
                return False, f"Clear predicate mismatch for block {block} (is_clear={is_clear}, in_clear_set={should_be_clear})"

        return True, None

    def __hash__(self):
        """Make state hashable for deduplication."""
        on_tuple = tuple(sorted((k, v) for k, v in self.on.items()))
        return hash((
            frozenset(self.on_table),
            on_tuple,
            frozenset(self.clear),
            self.arm_empty,
            self.holding
        ))

    def __eq__(self, other):
        """Check state equality."""
        if not isinstance(other, BlocksWorldState):
            return False
        return (
                self.on_table == other.on_table and
                self.on == other.on and
                self.clear == other.clear and
                self.arm_empty == other.arm_empty and
                self.holding == other.holding
        )

    def __repr__(self):
        parts = []
        if self.on_table:
            parts.append(f"on_table={self.on_table}")
        if self.on:
            parts.append(f"on={self.on}")
        if self.clear:
            parts.append(f"clear={self.clear}")
        parts.append(f"arm_empty={self.arm_empty}")
        if self.holding:
            parts.append(f"holding={self.holding}")
        return f"State({', '.join(parts)})"


def create_empty_state(block_names: list) -> BlocksWorldState:
    """
    Create an empty initial state: all blocks on table, arm empty, all clear.

    Requirement #14: Start with a valid state.
    """
    state = BlocksWorldState(
        blocks=set(block_names),
        on_table=set(block_names),
        on={},
        clear=set(block_names),
        arm_empty=True,
        holding=None
    )
    is_valid, error = state.is_valid()
    if not is_valid:
        raise ValueError(f"Failed to create empty state: {error}")
    return state

--------------------------------------------------------------------------------

The file actions.py code is this:
"""
Action definitions and execution for Blocksworld.

Implements forward and reverse execution of the four actions:
1. pickup ?ob (from table)
2. putdown ?ob (onto table)
3. stack ?ob ?underob (onto another block)
4. unstack ?ob ?underob (from another block)
"""

from typing import List, Optional, Tuple
from enum import Enum
from state import BlocksWorldState


class ActionType(Enum):
    PICKUP = "pickup"
    PUTDOWN = "putdown"
    STACK = "stack"
    UNSTACK = "unstack"


class Action:
    """Represents an action in Blocksworld."""

    def __init__(self, action_type: ActionType, params: List[str]):
        self.action_type = action_type
        self.params = params

    def __repr__(self):
        return f"{self.action_type.value}({', '.join(self.params)})"

    def __eq__(self, other):
        if not isinstance(other, Action):
            return False
        return self.action_type == other.action_type and self.params == other.params

    def __hash__(self):
        return hash((self.action_type, tuple(self.params)))


class ActionExecutor:
    """Executes actions on Blocksworld states."""

    @staticmethod
    def can_execute_pickup(state: BlocksWorldState, ob: str) -> bool:
        """
        Check preconditions for pickup:
        - arm-empty
        - on-table ?ob
        - clear ?ob
        """
        return (
                state.arm_empty and
                ob in state.on_table and
                ob in state.clear
        )

    @staticmethod
    def execute_pickup(state: BlocksWorldState, ob: str) -> Optional[BlocksWorldState]:
        """Execute pickup action."""
        if not ActionExecutor.can_execute_pickup(state, ob):
            return None

        new_state = state.copy()
        new_state.arm_empty = False
        new_state.holding = ob
        new_state.on_table.discard(ob)
        new_state.clear.discard(ob)

        is_valid, error = new_state.is_valid()
        return new_state if is_valid else None

    @staticmethod
    def can_execute_putdown(state: BlocksWorldState, ob: str) -> bool:
        """
        Check preconditions for putdown:
        - holding ?ob
        """
        return state.holding == ob

    @staticmethod
    def execute_putdown(state: BlocksWorldState, ob: str) -> Optional[BlocksWorldState]:
        """Execute putdown action."""
        if not ActionExecutor.can_execute_putdown(state, ob):
            return None

        new_state = state.copy()
        new_state.arm_empty = True
        new_state.holding = None
        new_state.on_table.add(ob)
        new_state.clear.add(ob)

        is_valid, error = new_state.is_valid()
        return new_state if is_valid else None

    @staticmethod
    def can_execute_stack(state: BlocksWorldState, ob: str, underob: str) -> bool:
        """
        Check preconditions for stack:
        - holding ?ob
        - clear ?underob
        - ob != underob
        """
        return (
                state.holding == ob and
                underob in state.clear and
                ob != underob
        )

    @staticmethod
    def execute_stack(state: BlocksWorldState, ob: str, underob: str) -> Optional[BlocksWorldState]:
        """Execute stack action."""
        if not ActionExecutor.can_execute_stack(state, ob, underob):
            return None

        new_state = state.copy()
        new_state.arm_empty = True
        new_state.holding = None
        new_state.on[ob] = underob
        new_state.clear.add(ob)
        new_state.clear.discard(underob)

        is_valid, error = new_state.is_valid()
        return new_state if is_valid else None

    @staticmethod
    def can_execute_unstack(state: BlocksWorldState, ob: str, underob: str) -> bool:
        """
        Check preconditions for unstack:
        - on ?ob ?underob
        - clear ?ob
        - arm-empty
        """
        return (
                state.on.get(ob) == underob and
                ob in state.clear and
                state.arm_empty
        )

    @staticmethod
    def execute_unstack(state: BlocksWorldState, ob: str, underob: str) -> Optional[BlocksWorldState]:
        """Execute unstack action."""
        if not ActionExecutor.can_execute_unstack(state, ob, underob):
            return None

        new_state = state.copy()
        new_state.arm_empty = False
        new_state.holding = ob
        del new_state.on[ob]
        new_state.clear.discard(ob)
        new_state.clear.add(underob)

        is_valid, error = new_state.is_valid()
        return new_state if is_valid else None

    @staticmethod
    def execute_forward(state: BlocksWorldState, action: Action) -> Optional[BlocksWorldState]:
        """
        Execute an action in the forward direction.

        Returns the resulting state, or None if action is not applicable.
        """
        if action.action_type == ActionType.PICKUP:
            return ActionExecutor.execute_pickup(state, action.params[0])
        elif action.action_type == ActionType.PUTDOWN:
            return ActionExecutor.execute_putdown(state, action.params[0])
        elif action.action_type == ActionType.STACK:
            return ActionExecutor.execute_stack(state, action.params[0], action.params[1])
        elif action.action_type == ActionType.UNSTACK:
            return ActionExecutor.execute_unstack(state, action.params[0], action.params[1])
        else:
            return None

    @staticmethod
    def get_applicable_actions(state: BlocksWorldState) -> List[Action]:
        """Get all applicable actions in the current state (forward direction)."""
        applicable = []

        # Pickup actions
        for block in state.blocks:
            if ActionExecutor.can_execute_pickup(state, block):
                applicable.append(Action(ActionType.PICKUP, [block]))

        # Putdown actions
        if state.holding:
            if ActionExecutor.can_execute_putdown(state, state.holding):
                applicable.append(Action(ActionType.PUTDOWN, [state.holding]))

        # Stack actions
        if state.holding:
            for underob in state.blocks:
                if underob != state.holding:
                    if ActionExecutor.can_execute_stack(state, state.holding, underob):
                        applicable.append(Action(ActionType.STACK, [state.holding, underob]))

        # Unstack actions
        if state.arm_empty:
            for ob, underob in state.on.items():
                if ActionExecutor.can_execute_unstack(state, ob, underob):
                    applicable.append(Action(ActionType.UNSTACK, [ob, underob]))

        return applicable

--------------------------------------------------------------------------------

The file goal_archetypes.py code is this:
"""
Goal archetypes for Blocksworld.

Defines different types of goals to ensure structural diversity (Requirement #2).
Active archetype selection ensures variety in problem structures.
"""

import random
from typing import List, Tuple, Callable
from enum import Enum
from state import BlocksWorldState


class GoalArchetype(Enum):
    """Different goal archetype types."""
    SINGLE_TOWER = "single_tower"
    MULTIPLE_TOWERS = "multiple_towers"
    CLEAR_TABLE = "clear_table"
    SCATTERED_RELATIONS = "scattered_relations"
    MIXED_PYRAMID = "mixed_pyramid"


class GoalArchetypeGenerator:
    """
    Generates goal states according to different archetypes.

    Requirement #4: Active sampling of goal archetypes to guarantee variety.
    """

    def __init__(self, random_seed: int = None):
        self.random_seed = random_seed
        if random_seed is not None:
            random.seed(random_seed)

    def generate_single_tower(self, blocks: List[str]) -> BlocksWorldState:
        """
        Archetype: Single tall tower.
        All blocks stacked into one tall tower.
        """
        state = BlocksWorldState(
            blocks=set(blocks),
            on_table={blocks[0]},
            on={},
            clear=set(),
            arm_empty=True,
            holding=None
        )

        # Stack remaining blocks on top
        for i in range(1, len(blocks)):
            state.on[blocks[i]] = blocks[i - 1]

        state.clear.add(blocks[-1])

        is_valid, error = state.is_valid()
        if not is_valid:
            raise ValueError(f"Invalid single tower state: {error}")
        return state

    def generate_multiple_towers(self, blocks: List[str], num_towers: int = 2) -> BlocksWorldState:
        """
        Archetype: Multiple towers.
        Distribute blocks among num_towers separate stacks.
        """
        num_towers = min(num_towers, len(blocks))

        state = BlocksWorldState(
            blocks=set(blocks),
            on_table=set(),
            on={},
            clear=set(),
            arm_empty=True,
            holding=None
        )

        # Distribute blocks among towers
        tower_assignments = [[] for _ in range(num_towers)]
        for i, block in enumerate(blocks):
            tower_assignments[i % num_towers].append(block)

        # Build each tower
        for tower_blocks in tower_assignments:
            if tower_blocks:
                state.on_table.add(tower_blocks[0])
                for i in range(1, len(tower_blocks)):
                    state.on[tower_blocks[i]] = tower_blocks[i - 1]
                state.clear.add(tower_blocks[-1])

        is_valid, error = state.is_valid()
        if not is_valid:
            raise ValueError(f"Invalid multiple towers state: {error}")
        return state

    def generate_clear_table(self, blocks: List[str]) -> BlocksWorldState:
        """
        Archetype: All blocks on table.
        No stacking; all blocks sitting on the table, all clear.
        """
        state = BlocksWorldState(
            blocks=set(blocks),
            on_table=set(blocks),
            on={},
            clear=set(blocks),
            arm_empty=True,
            holding=None
        )

        is_valid, error = state.is_valid()
        if not is_valid:
            raise ValueError(f"Invalid clear table state: {error}")
        return state

    def generate_scattered_relations(self, blocks: List[str]) -> BlocksWorldState:
        """
        Archetype: Scattered on/on-table relations.
        Create a few random on/on-table relations without forming complete towers.
        """
        state = BlocksWorldState(
            blocks=set(blocks),
            on_table=set(),
            on={},
            clear=set(),
            arm_empty=True,
            holding=None
        )

        # Randomly decide which blocks are on the table
        shuffled = blocks.copy()
        random.shuffle(shuffled)
        base_blocks = set(shuffled[: max(1, len(blocks) // 2)])

        state.on_table = base_blocks.copy()
        state.clear = base_blocks.copy()

        # Place remaining blocks on random base blocks
        non_base = [b for b in blocks if b not in base_blocks]
        for block in non_base:
            if state.clear:  # Only place if there's a clear block
                under = random.choice(list(state.clear))
                state.on[block] = under
                state.clear.discard(under)

        state.clear.update([b for b in blocks if b not in state.on.values()])

        is_valid, error = state.is_valid()
        if not is_valid:
            # Fallback to simple valid state
            return self.generate_multiple_towers(blocks, 2)
        return state

    def generate_mixed_pyramid(self, blocks: List[str]) -> BlocksWorldState:
        """
        Archetype: Pyramid-like structure.
        Create a structure with decreasing blocks per level.
        """
        if len(blocks) < 3:
            return self.generate_multiple_towers(blocks, 2)

        state = BlocksWorldState(
            blocks=set(blocks),
            on_table=set(),
            on={},
            clear=set(),
            arm_empty=True,
            holding=None
        )

        shuffled = blocks.copy()
        random.shuffle(shuffled)

        # First block(s) on table
        state.on_table.add(shuffled[0])
        idx = 1

        # Stack blocks in a pyramid
        for i in range(1, len(shuffled)):
            if i % 2 == 0:  # Decide structure
                state.on[shuffled[i]] = shuffled[i - 1]
            else:
                if len(state.on_table) < max(1, len(blocks) // 3):
                    state.on_table.add(shuffled[i])
                else:
                    state.on[shuffled[i]] = shuffled[i - 1]

        # Update clear
        state.clear = {b for b in blocks if b not in state.on.values()}

        is_valid, error = state.is_valid()
        if not is_valid:
            return self.generate_multiple_towers(blocks, 2)
        return state

    def generate_archetype(self, archetype: GoalArchetype, blocks: List[str]) -> BlocksWorldState:
        """Generate a goal state for the given archetype."""
        if archetype == GoalArchetype.SINGLE_TOWER:
            return self.generate_single_tower(blocks)
        elif archetype == GoalArchetype.MULTIPLE_TOWERS:
            num_towers = random.randint(2, max(2, len(blocks) // 2))
            return self.generate_multiple_towers(blocks, num_towers)
        elif archetype == GoalArchetype.CLEAR_TABLE:
            return self.generate_clear_table(blocks)
        elif archetype == GoalArchetype.SCATTERED_RELATIONS:
            return self.generate_scattered_relations(blocks)
        elif archetype == GoalArchetype.MIXED_PYRAMID:
            return self.generate_mixed_pyramid(blocks)
        else:
            raise ValueError(f"Unknown archetype: {archetype}")

    def generate_random_archetype(self, blocks: List[str]) -> Tuple[BlocksWorldState, GoalArchetype]:
        """Generate a random archetype (Requirement #4)."""
        archetype = random.choice(list(GoalArchetype))
        state = self.generate_archetype(archetype, blocks)
        return state, archetype

--------------------------------------------------------------------------------

The file backward_generator.py code is this:
"""
Core backward search generator for problem generation.

Requirement #14: Generate problems using backward state-space search.
- Start with a structurally diverse goal state
- Apply valid actions in reverse
- Walk back to a derived initial state
"""

import random
from typing import List, Tuple, Optional
from state import BlocksWorldState, create_empty_state
from actions import Action, ActionType, ActionExecutor
from goal_archetypes import GoalArchetypeGenerator, GoalArchetype


class ReverseActionExecutor:
    """
    Executes actions in reverse to generate problems.

    For each forward action, we implement its reverse:
    - pickup (forward) <-> putdown (reverse)
    - stack (forward) <-> unstack (reverse)
    - unstack (forward) <-> pickup (reverse)
    - putdown (forward) <-> stack (reverse)
    """

    @staticmethod
    def reverse_pickup(state: BlocksWorldState, ob: str) -> Optional[BlocksWorldState]:
        """
        Reverse of pickup: arm was holding block, put it back on table.
        This is equivalent to forward putdown.
        """
        return ActionExecutor.execute_putdown(state, ob)

    @staticmethod
    def reverse_putdown(state: BlocksWorldState, ob: str) -> Optional[BlocksWorldState]:
        """
        Reverse of putdown: arm was empty, pick up the block from table.
        This is equivalent to forward pickup.
        """
        return ActionExecutor.execute_pickup(state, ob)

    @staticmethod
    def reverse_stack(state: BlocksWorldState, ob: str, underob: str) -> Optional[BlocksWorldState]:
        """
        Reverse of stack: unstack the block.
        This is equivalent to forward unstack.
        """
        return ActionExecutor.execute_unstack(state, ob, underob)

    @staticmethod
    def reverse_unstack(state: BlocksWorldState, ob: str, underob: str) -> Optional[BlocksWorldState]:
        """
        Reverse of unstack: arm was empty, stack the block.
        This is equivalent to forward stack.
        """
        return ActionExecutor.execute_stack(state, ob, underob)

    @staticmethod
    def execute_reverse(state: BlocksWorldState, action: Action) -> Optional[BlocksWorldState]:
        """Execute an action in reverse."""
        if action.action_type == ActionType.PICKUP:
            return ReverseActionExecutor.reverse_pickup(state, action.params[0])
        elif action.action_type == ActionType.PUTDOWN:
            return ReverseActionExecutor.reverse_putdown(state, action.params[0])
        elif action.action_type == ActionType.STACK:
            return ReverseActionExecutor.reverse_stack(state, action.params[0], action.params[1])
        elif action.action_type == ActionType.UNSTACK:
            return ReverseActionExecutor.reverse_unstack(state, action.params[0], action.params[1])
        else:
            return None

    @staticmethod
    def get_applicable_reverse_actions(state: BlocksWorldState) -> List[Action]:
        """
        Get all actions that can be applied in reverse from this state.

        An action can be reversed if its reverse application produces a
        valid new state that is different from the current state.

        Requirement #14: Ensure backward search actually progresses.
        """
        applicable = []

        # Try all possible actions
        for block in state.blocks:
            # Try reverse_pickup (applies putdown)
            result = ReverseActionExecutor.reverse_pickup(state, block)
            if result is not None and result != state:
                # Avoid cycles
                applicable.append(Action(ActionType.PICKUP, [block]))

            # Try reverse_putdown (applies pickup)
            result = ReverseActionExecutor.reverse_putdown(state, block)
            if result is not None and result != state:
                applicable.append(Action(ActionType.PUTDOWN, [block]))

            # Try reverse stack/unstack with all other blocks
            for other_block in state.blocks:
                if block != other_block:
                    # Try reverse_stack (applies unstack)
                    result = ReverseActionExecutor.reverse_stack(state, block, other_block)
                    if result is not None and result != state:
                        applicable.append(Action(ActionType.STACK, [block, other_block]))

                    # Try reverse_unstack (applies stack)
                    result = ReverseActionExecutor.reverse_unstack(state, block, other_block)
                    if result is not None and result != state:
                        applicable.append(Action(ActionType.UNSTACK, [block, other_block]))

        # Remove duplicates while preserving order
        seen = set()
        unique_applicable = []
        for action in applicable:
            action_tuple = (action.action_type, tuple(action.params))
            if action_tuple not in seen:
                seen.add(action_tuple)
                unique_applicable.append(action)

        return unique_applicable


class BackwardProblemGenerator:
    """
    Generate Blocksworld problems using backward state-space search.

    Algorithm:
    1. Select a goal archetype
    2. Generate a valid goal state
    3. Perform N random valid reverse actions from the goal
    4. Result: derived initial state + path = known plan

    Requirement #14: Guaranteed solvability and known plan cost.
    """

    def __init__(self, random_seed: int = None):
        self.random_seed = random_seed
        self.archetype_gen = GoalArchetypeGenerator(random_seed)
        if random_seed is not None:
            random.seed(random_seed)

    def generate_problem(
            self,
            num_blocks: int,
            target_plan_length: int,
            archetype: Optional[GoalArchetype] = None,
            tolerance: int = 1
    ) -> Tuple[BlocksWorldState, BlocksWorldState, List[Action], GoalArchetype]:
        """
        Generate a problem using backward search.

        Args:
            num_blocks: Number of blocks to use
            target_plan_length: Desired length of the plan (path)
            archetype: Goal archetype (random if None)
            tolerance: Allowed deviation from target length

        Returns:
            (initial_state, goal_state, plan, archetype_used)

        Requirement #15: Inherent guarantees (solvability and known plan).
        """
        block_names = [f"b{i}" for i in range(num_blocks)]

        # Step 1: Generate or select goal state (Req #3, #4)
        if archetype is None:
            goal_state, archetype = self.archetype_gen.generate_random_archetype(block_names)
        else:
            goal_state = self.archetype_gen.generate_archetype(archetype, block_names)

        # Verify goal is valid (Req #14)
        is_valid, error = goal_state.is_valid()
        if not is_valid:
            raise ValueError(f"Generated invalid goal state: {error}")

        # Step 2: Backward search from goal state
        current_state = goal_state.copy()
        plan = []
        max_attempts = target_plan_length + tolerance + 10  # Safety margin

        while len(plan) < target_plan_length and max_attempts > 0:
            # Get all reverse actions applicable in current state
            reverse_actions = ReverseActionExecutor.get_applicable_reverse_actions(current_state)

            if not reverse_actions:
                # No more actions available; stop here
                break

            # Randomly select a reverse action
            action = random.choice(reverse_actions)
            new_state = ReverseActionExecutor.execute_reverse(current_state, action)

            if new_state is None:
                max_attempts -= 1
                continue

            is_valid, error = new_state.is_valid()
            if not is_valid:
                max_attempts -= 1
                continue

            # Record the action in reverse order (for forward execution)
            plan.insert(0, action)
            current_state = new_state
            max_attempts -= 1

        # Step 3: Validate plan length
        if not (target_plan_length - tolerance <= len(plan) <= target_plan_length + tolerance):
            # Plan length out of target range; return anyway but note the deviation
            pass

        initial_state = current_state

        # Requirement #15: Verify the plan is valid
        if not self._verify_plan(initial_state, goal_state, plan):
            raise RuntimeError("Generated plan does not reach goal from initial state")

        return initial_state, goal_state, plan, archetype

    def _verify_plan(
            self,
            initial_state: BlocksWorldState,
            goal_state: BlocksWorldState,
            plan: List[Action]
    ) -> bool:
        """
        Verify that the plan reaches goal from initial state.
        """
        current = initial_state.copy()
        for action in plan:
            current = ActionExecutor.execute_forward(current, action)
            if current is None:
                return False
        return current == goal_state

--------------------------------------------------------------------------------

The file pddl_writer.py code is this:
"""
PDDL file generation.

Outputs valid PDDL domain and problem files according to Requirement #10.
"""

from typing import List, Optional
from state import BlocksWorldState
from actions import Action, ActionType


class PDDLWriter:
    """Writes PDDL domain and problem files."""

    DOMAIN_TEMPLATE = """(define (domain blocksworld)
  (:requirements :strips)
  (:predicates (clear ?x)
               (on-table ?x)
               (arm-empty)
               (holding ?x)
               (on ?x ?y))

  (:action pickup
    :parameters (?ob)
    :precondition (and (clear ?ob) (on-table ?ob) (arm-empty))
    :effect (and (holding ?ob) (not (clear ?ob)) (not (on-table ?ob)) 
                 (not (arm-empty))))

  (:action putdown
    :parameters  (?ob)
    :precondition (holding ?ob)
    :effect (and (clear ?ob) (arm-empty) (on-table ?ob) 
                 (not (holding ?ob))))

  (:action stack
    :parameters  (?ob ?underob)
    :precondition (and (clear ?underob) (holding ?ob))
    :effect (and (arm-empty) (clear ?ob) (on ?ob ?underob)
                 (not (clear ?underob)) (not (holding ?ob))))

  (:action unstack
    :parameters  (?ob ?underob)
    :precondition (and (on ?ob ?underob) (clear ?ob) (arm-empty))
    :effect (and (holding ?ob) (clear ?underob)
                 (not (on ?ob ?underob)) (not (clear ?ob)) (not (arm-empty)))))
"""

    @staticmethod
    def write_domain(filepath: str) -> None:
        """Write the Blocksworld domain file."""
        with open(filepath, 'w') as f:
            f.write(PDDLWriter.DOMAIN_TEMPLATE)

    @staticmethod
    def state_to_init_pddl(state: BlocksWorldState) -> str:
        """Convert a state to PDDL :init format."""
        facts = []

        # on-table facts
        for block in sorted(state.on_table):
            facts.append(f"(on-table {block})")

        # on facts
        for block, underblock in sorted(state.on.items()):
            facts.append(f"(on {block} {underblock})")

        # clear facts
        for block in sorted(state.clear):
            facts.append(f"(clear {block})")

        # arm state
        if state.arm_empty:
            facts.append("(arm-empty)")
        if state.holding:
            facts.append(f"(holding {state.holding})")

        return " ".join(facts)

    @staticmethod
    def state_to_goal_pddl(state: BlocksWorldState) -> str:
        """Convert a state to PDDL :goal format."""
        facts = []

        # on-table facts
        for block in sorted(state.on_table):
            facts.append(f"(on-table {block})")

        # on facts
        for block, underblock in sorted(state.on.items()):
            facts.append(f"(on {block} {underblock})")

        # clear facts
        for block in sorted(state.clear):
            facts.append(f"(clear {block})")

        # arm state (usually arm-empty in goals)
        if state.arm_empty:
            facts.append("(arm-empty)")
        if state.holding:
            facts.append(f"(holding {state.holding})")

        if len(facts) == 1:
            return facts[0]
        return "(and " + " ".join(facts) + ")"

    @staticmethod
    def write_problem(
            filepath: str,
            problem_name: str,
            initial_state: BlocksWorldState,
            goal_state: BlocksWorldState
    ) -> None:
        """
        Write a PDDL problem file.

        Requirement #10: Standard .pddl file format.
        """
        blocks = sorted(initial_state.blocks)
        objects_str = " ".join(blocks)

        init_str = PDDLWriter.state_to_init_pddl(initial_state)
        goal_str = PDDLWriter.state_to_goal_pddl(goal_state)

        problem_pddl = f"""(define (problem {problem_name})
  (:domain blocksworld)
  (:objects {objects_str})
  (:init
    {init_str}
  )
  (:goal
    {goal_str}
  )
)
"""
        with open(filepath, 'w') as f:
            f.write(problem_pddl)

--------------------------------------------------------------------------------

The file baseline_planner.py code is this:
"""
Integration with Fast Downward baseline planner.

FIXED VERSION: Proper timeout enforcement with process termination guarantee.
"""

import subprocess
import json
import re
import os
import time
import logging
import signal
import sys
from typing import Optional, Dict, Any
from pathlib import Path

logger = logging.getLogger(__name__)


class FastDownwardRunner:
    """Runs Fast Downward with guaranteed timeout enforcement."""

    def __init__(self, timeout: int = 260):  # ← FIXED: Changed from 600 to 260
        """
        Initialize Fast Downward runner.

        Args:
            timeout: Maximum time in seconds for SEARCH PHASE ONLY (default: 260)
        """
        self.timeout = timeout

        script_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.abspath(os.path.join(script_dir, ".."))
        fd_bin_dir = os.path.join(project_root, "downward", "builds", "release", "bin")

        if os.name == 'nt':  # Windows
            self.fd_bin = os.path.join(fd_bin_dir, "downward.exe")
        else:  # Linux/macOS
            self.fd_bin = os.path.join(fd_bin_dir, "downward")

        self.fd_translate = os.path.join(fd_bin_dir, "translate", "translate.py")
        self.temp_dir = os.path.join(project_root, "generation_temp")
        os.makedirs(self.temp_dir, exist_ok=True)

        self.fd_available = self._check_fd_available()

    def _check_fd_available(self) -> bool:
        """Check if Fast Downward binaries are available."""
        fd_exists = os.path.exists(self.fd_bin)
        translate_exists = os.path.exists(self.fd_translate)

        if not fd_exists or not translate_exists:
            logger.warning("Fast Downward not fully available:")
            if not fd_exists:
                logger.warning(f"  ✗ Binary not found: {self.fd_bin}")
            if not translate_exists:
                logger.warning(f"  ✗ Translator not found: {self.fd_translate}")
            return False

        logger.debug(f"✓ FD binary: {self.fd_bin}")
        logger.debug(f"✓ FD translator: {self.fd_translate}")
        return True

    def run_problem(
            self,
            domain_file: str,
            problem_file: str,
            search_config: str = "astar(lmcut())",
            timeout: Optional[int] = None
    ) -> Dict[str, Any]:
        """
        Run Fast Downward on a problem using 2-step translate/search process.

        FIXED: Proper timeout enforcement for search phase.

        Args:
            domain_file: Path to domain PDDL file
            problem_file: Path to problem PDDL file
            search_config: Fast Downward search configuration string
            timeout: Maximum time in seconds for SEARCH PHASE ONLY

        Returns:
            Dict with search results and metrics
        """
        if not self.fd_available:
            return {
                "success": False,
                "time": 0,
                "plan_cost": None,
                "nodes_expanded": None,
                "nodes_generated": None,
                "search_depth": None,
                "plan": None,
                "error": "Fast Downward not installed or not found at expected paths"
            }

        # FIXED: Use provided timeout or fall back to self.timeout
        search_timeout = timeout if timeout is not None else self.timeout
        translate_timeout = 300

        logger.info(f"[TIMEOUT CONFIG] Translate: {translate_timeout}s, Search: {search_timeout}s")

        overall_start_time = time.time()
        problem_name = os.path.basename(problem_file)
        sas_file = os.path.join(self.temp_dir, "output.sas")

        try:
            # ==========================================================
            # PHASE 1: TRANSLATE (PDDL -> SAS)
            # ==========================================================
            logger.debug(f"[TRANSLATE] {problem_name}")
            translate_start = time.time()

            abs_domain = os.path.abspath(domain_file)
            abs_problem = os.path.abspath(problem_file)

            translate_cmd = (
                f'python "{self.fd_translate}" "{abs_domain}" '
                f'"{abs_problem}" --sas-file "{sas_file}"'
            )

            try:
                translate_result = subprocess.run(
                    translate_cmd,
                    shell=True,
                    cwd=os.path.abspath(".."),
                    capture_output=True,
                    text=True,
                    timeout=translate_timeout
                )
            except subprocess.TimeoutExpired:
                logger.warning(f"[TRANSLATE TIMEOUT] Exceeded {translate_timeout}s for {problem_name}")
                return {
                    "success": False,
                    "time": time.time() - overall_start_time,
                    "plan_cost": None,
                    "nodes_expanded": None,
                    "nodes_generated": None,
                    "search_depth": None,
                    "plan": None,
                    "error": f"Translate timeout (>{translate_timeout}s)"
                }

            translate_time = time.time() - translate_start

            if translate_result.returncode != 0:
                error_msg = translate_result.stderr if translate_result.stderr else translate_result.stdout
                logger.debug(f"[TRANSLATE] Failed: {error_msg[:200]}")
                return {
                    "success": False,
                    "time": time.time() - overall_start_time,
                    "plan_cost": None,
                    "nodes_expanded": None,
                    "nodes_generated": None,
                    "search_depth": None,
                    "plan": None,
                    "error": f"Translate error: {error_msg[:300]}"
                }

            if not os.path.exists(sas_file):
                logger.debug(f"[TRANSLATE] Failed: SAS file not created")
                return {
                    "success": False,
                    "time": time.time() - overall_start_time,
                    "plan_cost": None,
                    "nodes_expanded": None,
                    "nodes_generated": None,
                    "search_depth": None,
                    "plan": None,
                    "error": "Translate: SAS file not created"
                }

            logger.debug(f"[TRANSLATE] Success ({os.path.getsize(sas_file)} bytes) in {translate_time:.2f}s")

            # ==========================================================
            # PHASE 2: SEARCH (SAS -> Plan)
            # FIXED: Use robust subprocess handling to enforce timeout
            # ==========================================================
            logger.debug(f"[SEARCH] Starting with config: {search_config}, timeout: {search_timeout}s")
            search_start = time.time()

            # FIXED: Use Popen + communicate for better timeout control
            search_cmd_list = [
                self.fd_bin,
                "--search", search_config
            ]

            try:
                # Open SAS file for stdin
                with open(sas_file, 'r') as sas_input:
                    search_process = subprocess.Popen(
                        search_cmd_list,
                        stdin=sas_input,
                        stdout=subprocess.PIPE,
                        stderr=subprocess.PIPE,
                        text=True,
                        cwd=os.path.dirname(self.fd_bin)
                    )

                    try:
                        stdout_text, stderr_text = search_process.communicate(timeout=search_timeout)
                        search_returncode = search_process.returncode
                    except subprocess.TimeoutExpired:
                        # FIXED: Kill the process tree
                        logger.warning(f"[SEARCH TIMEOUT] Killing process after {search_timeout}s")
                        try:
                            if sys.platform == 'win32':
                                # Windows: use SIGKILL equivalent
                                search_process.kill()
                            else:
                                # Unix: first try SIGTERM, then SIGKILL
                                search_process.terminate()
                                try:
                                    search_process.wait(timeout=5)
                                except subprocess.TimeoutExpired:
                                    search_process.kill()
                            search_process.wait()
                        except Exception as e:
                            logger.debug(f"Error terminating process: {e}")

                        return {
                            "success": False,
                            "time": time.time() - overall_start_time,
                            "plan_cost": None,
                            "nodes_expanded": None,
                            "nodes_generated": None,
                            "search_depth": None,
                            "plan": None,
                            "error": f"Search timeout (>{search_timeout}s)"
                        }

                search_time = time.time() - search_start
                total_time = time.time() - overall_start_time

                output_text = stdout_text + stderr_text

                logger.debug(f"[SEARCH] Completed in {search_time:.2f}s (total: {total_time:.2f}s)")

            except Exception as e:
                logger.error(f"[SEARCH] Exception: {e}")
                return {
                    "success": False,
                    "time": time.time() - overall_start_time,
                    "plan_cost": None,
                    "nodes_expanded": None,
                    "nodes_generated": None,
                    "search_depth": None,
                    "plan": None,
                    "error": f"Search error: {str(e)[:200]}"
                }

            # Clean up SAS file
            try:
                if os.path.exists(sas_file):
                    os.remove(sas_file)
            except Exception as e:
                logger.debug(f"Could not remove SAS file: {e}")

            # ==========================================================
            # PHASE 3: PARSE OUTPUT
            # ==========================================================

            solution_found = (
                    "Solution found" in output_text or
                    "Plan length:" in output_text
            )

            if not solution_found:
                logger.debug(f"[PARSE] No solution found")
                return {
                    "success": False,
                    "time": total_time,
                    "plan_cost": None,
                    "nodes_expanded": None,
                    "nodes_generated": None,
                    "search_depth": None,
                    "plan": None,
                    "error": "No solution found"
                }

            metrics = self._parse_fd_output(output_text)

            logger.debug(
                f"[SUCCESS] cost={metrics['plan_cost']}, "
                f"exp={metrics['nodes_expanded']}, "
                f"time={total_time:.2f}s"
            )

            return {
                "success": True,
                "time": total_time,
                "plan_cost": metrics['plan_cost'],
                "nodes_expanded": metrics['nodes_expanded'],
                "nodes_generated": metrics['nodes_generated'],
                "search_depth": metrics['search_depth'],
                "plan": metrics['plan'],
                "error": None
            }

        except Exception as e:
            logger.error(f"[ERROR] Unexpected exception: {e}")
            return {
                "success": False,
                "time": time.time() - overall_start_time,
                "plan_cost": None,
                "nodes_expanded": None,
                "nodes_generated": None,
                "search_depth": None,
                "plan": None,
                "error": f"Exception: {str(e)[:200]}"
            }

    @staticmethod
    def _parse_fd_output(output_text: str) -> Dict[str, Any]:
        """Extract comprehensive metrics from Fast Downward output."""
        result = {
            "plan_cost": None,
            "nodes_expanded": None,
            "nodes_generated": None,
            "search_depth": None,
            "plan": None
        }

        cost_match = re.search(r"Plan length:\s*(\d+)", output_text)
        if cost_match:
            result["plan_cost"] = int(cost_match.group(1))

        nodes_expanded_matches = list(re.finditer(r"Expanded\s+(\d+)\s+state", output_text))
        if nodes_expanded_matches:
            result["nodes_expanded"] = int(nodes_expanded_matches[-1].group(1))

        nodes_generated_matches = list(re.finditer(r"Generated\s+(\d+)\s+state", output_text))
        if nodes_generated_matches:
            result["nodes_generated"] = int(nodes_generated_matches[-1].group(1))

        depth_match = re.search(r"Search depth:\s*(\d+)", output_text)
        if depth_match:
            result["search_depth"] = int(depth_match.group(1))

        plan_section = re.search(
            r"Solution found\.\n(.*?)(?:Plan length:|$)",
            output_text,
            re.DOTALL
        )
        if plan_section:
            actions = []
            for line in plan_section.group(1).strip().split('\n'):
                line = line.strip()
                if line and line.startswith('('):
                    actions.append(line)
            if actions:
                result["plan"] = actions

        return result

--------------------------------------------------------------------------------

The file metadata_store.py code is this:
"""
Metadata storage and retrieval.

Stores metadata for each generated problem, including baseline planner metrics.
Requirement #6, #12: Metadata capture and storage.
"""

import json
import os
from typing import Dict, Any, List
from pathlib import Path
from dataclasses import dataclass, asdict


@dataclass
class ProblemMetadata:
    """Metadata for a single generated problem."""
    problem_name: str
    domain: str
    difficulty: str
    num_blocks: int
    goal_archetype: str
    plan_length: int  # Generated plan length
    optimal_plan_cost: int  # Known from generation

    # Baseline planner metrics
    planner_time: float  # seconds
    planner_success: bool
    nodes_expanded: int
    plan_cost: int  # Actual plan cost found by planner

    # Files
    domain_file: str
    problem_file: str


class MetadataStore:
    """Manages problem metadata storage and retrieval."""

    def __init__(self, metadata_dir: str):
        self.metadata_dir = metadata_dir
        os.makedirs(metadata_dir, exist_ok=True)
        self.metadata_index: Dict[str, ProblemMetadata] = {}
        self.load_all_metadata()

    def save_metadata(self, metadata: ProblemMetadata) -> None:
        """Save metadata for a single problem."""
        self.metadata_index[metadata.problem_name] = metadata
        self._write_json_metadata()

    def load_all_metadata(self) -> None:
        """Load all metadata from disk."""
        index_file = os.path.join(self.metadata_dir, "index.json")
        if os.path.exists(index_file):
            with open(index_file, 'r') as f:
                data = json.load(f)
                for problem_name, meta_dict in data.items():
                    self.metadata_index[problem_name] = ProblemMetadata(**meta_dict)

    def _write_json_metadata(self) -> None:
        """Write metadata index to JSON."""
        index_file = os.path.join(self.metadata_dir, "index.json")
        data = {
            name: asdict(meta)
            for name, meta in self.metadata_index.items()
        }
        with open(index_file, 'w') as f:
            json.dump(data, f, indent=2)

    def get_by_difficulty(self, difficulty: str) -> List[ProblemMetadata]:
        """Get all problems of a specific difficulty."""
        return [
            meta for meta in self.metadata_index.values()
            if meta.difficulty == difficulty
        ]

    def get_summary_stats(self) -> Dict[str, Any]:
        """Get summary statistics."""
        if not self.metadata_index:
            return {}

        by_difficulty = {}
        for difficulty in ['small', 'medium', 'large']:
            problems = self.get_by_difficulty(difficulty)
            if problems:
                times = [p.planner_time for p in problems if p.planner_time]
                successful = sum(1 for p in problems if p.planner_success)
                by_difficulty[difficulty] = {
                    "count": len(problems),
                    "successful": successful,
                    "avg_time": sum(times) / len(times) if times else None,
                    "max_time": max(times) if times else None,
                    "min_time": min(times) if times else None,
                }

        return by_difficulty

--------------------------------------------------------------------------------

The file validator.py code is this:
"""
PDDL syntax validation.

Requirement #8: Validate PDDL files using a standard parser/validator.
"""

import subprocess
from typing import Tuple, Optional


class PDDLValidator:
    """Validates PDDL files using VAL or similar tools."""

    def __init__(self, validator_path: str = "validate"):
        """
        Initialize validator.

        Args:
            validator_path: Path to VAL validator executable
        """
        self.validator_path = validator_path

    def validate_problem(
            self,
            domain_file: str,
            problem_file: str
    ) -> Tuple[bool, Optional[str]]:
        """
        Validate a PDDL problem file.

        Returns:
            (is_valid, error_message)
        """
        try:
            result = subprocess.run(
                [self.validator_path, domain_file, problem_file],
                capture_output=True,
                text=True,
                timeout=10
            )

            if result.returncode == 0:
                return True, None
            else:
                error = result.stderr if result.stderr else result.stdout
                return False, error[:500]  # Truncate if too long

        except FileNotFoundError:
            # Validator not found; skip validation
            return True, "Validator not found; skipping validation"
        except subprocess.TimeoutExpired:
            return False, "Validation timeout"

--------------------------------------------------------------------------------

The file main.py code is this:
"""
Main orchestration and CLI for the problem generation framework.

Requirement #9: Scalable generation of arbitrary numbers of problems.
Requirement #13: Simple, modular architecture.
Requirement #18: Selective manual validation.
Requirement #19: Executable Python codebase.
"""

import logging
logger = logging.getLogger(__name__)

import argparse
import os
import sys
import random
from typing import List, Dict, Optional
from pathlib import Path
import json

from config import (
    DIFFICULTY_TIERS,
    BASELINE_PLANNER_CONFIG,
    ensure_output_dirs,
    OUTPUT_DIR,
    DOMAIN_DIR,
    PROBLEMS_DIR,
    METADATA_DIR
)
from state import create_empty_state
from backward_generator import BackwardProblemGenerator
from pddl_writer import PDDLWriter
from baseline_planner import FastDownwardRunner
from metadata_store import MetadataStore, ProblemMetadata
from validator import PDDLValidator
from goal_archetypes import GoalArchetype


class ProblemGenerationFramework:
    """Main framework for problem generation and validation."""

    def __init__(self, random_seed: int = None):
        """Initialize the framework."""
        ensure_output_dirs()
        self.random_seed = random_seed
        if random_seed is not None:
            random.seed(random_seed)

        self.generator = BackwardProblemGenerator(random_seed=random_seed)
        self.pddl_writer = PDDLWriter()
        self.fd_runner = FastDownwardRunner()
        self.validator = PDDLValidator()
        self.metadata_store = MetadataStore(METADATA_DIR)

    def generate_batch(
            self,
            num_problems: int,
            difficulty: str,
            num_blocks: int = 4,
            domain_name: str = "blocksworld",
            skip_planner: bool = False,
            timeout: Optional[int] = None  # <-- ADD THIS
    ) -> List[str]:
        """Generate a batch of problems (Requirement #9)."""

        if difficulty not in DIFFICULTY_TIERS:
            raise ValueError(f"Unknown difficulty: {difficulty}")

        tier = DIFFICULTY_TIERS[difficulty]

        # FIXED: Ensure timeout is set
        if timeout is None:
            timeout = BASELINE_PLANNER_CONFIG['timeout']


        problem_names = []

        print(f"\n{'=' * 70}")
        print(f"Generating {num_problems} {difficulty} problems")
        print(f"Target plan length: {tier.target_length}")
        print(f"Number of blocks: {num_blocks}")
        print(f"Planner timeout: {timeout} seconds per problem")  # ADDED
        if skip_planner:
            print("(Baseline planner disabled)")
        print(f"{'=' * 70}\n")

        for i in range(num_problems):
            try:
                # Generate problem
                initial_state, goal_state, plan, archetype = self.generator.generate_problem(
                    num_blocks=num_blocks,
                    target_plan_length=tier.target_length,
                    tolerance=1
                )

                problem_name = f"{domain_name}-{difficulty}-{i}"
                problem_names.append(problem_name)

                # Write PDDL files
                domain_file = os.path.join(DOMAIN_DIR, f"{domain_name}.pddl")
                problem_file = os.path.join(PROBLEMS_DIR, f"{problem_name}.pddl")

                if i == 0:
                    self.pddl_writer.write_domain(domain_file)

                self.pddl_writer.write_problem(
                    problem_file,
                    problem_name,
                    initial_state,
                    goal_state
                )

                # Validate PDDL syntax (Requirement #8)
                is_valid, error = self.validator.validate_problem(domain_file, problem_file)
                if not is_valid:
                    print(f"  Problem {i}: PDDL validation failed: {error}")
                    continue

                print(f"  Problem {i}: ", end='', flush=True)

                # Run baseline planner if available (Requirement #12)
                if skip_planner:
                    print("✓ Generated (planner skipped)")
                    planner_result = {
                        'success': True,
                        'time': None,
                        'plan_cost': len(plan),
                        'nodes_expanded': None,
                        'error': None
                    }
                else:
                    try:
                        planner_result = self.fd_runner.run_problem(
                            domain_file,
                            problem_file,
                            search_config="astar(lmcut())",
                            timeout=timeout  # <-- CHANGE THIS LINE
                        )

                        if planner_result['success']:
                            print(
                                f"✓ Time: {planner_result['time']:.2f}s, "
                                f"Cost: {planner_result['plan_cost']}, "
                                f"Nodes: {planner_result['nodes_expanded']}"
                            )
                        else:
                            print(f"✗ Failed: {planner_result['error']}")
                    except Exception as e:
                        logger.error(f"Planner execution error: {e}")
                        planner_result = {
                            'success': False,
                            'time': 0,
                            'plan_cost': None,
                            'nodes_expanded': None,
                            'error': str(e)[:200]
                        }
                        print(f"✗ Planner error: {str(e)[:50]}")

                # Store metadata (Requirement #6, #12)
                metadata = ProblemMetadata(
                    problem_name=problem_name,
                    domain=domain_name,
                    difficulty=difficulty,
                    num_blocks=num_blocks,
                    goal_archetype=archetype.value,
                    plan_length=len(plan),
                    optimal_plan_cost=len(plan),
                    planner_time=planner_result.get('time', 0),
                    planner_success=planner_result.get('success', False),
                    nodes_expanded=planner_result.get('nodes_expanded', 0),
                    plan_cost=planner_result.get('plan_cost', len(plan)),
                    domain_file=domain_file,
                    problem_file=problem_file
                )
                self.metadata_store.save_metadata(metadata)

            except Exception as e:
                print(f"  Problem {i}: Error: {e}")
                logger.error(f"Problem generation error: {e}", exc_info=True)
                continue

        print(f"\nGenerated {len(problem_names)}/{num_problems} problems successfully\n")
        return problem_names

    def validate_subset(self, difficulty: str, count: int = 5) -> None:
        """
        Validate a subset of problems (Requirement #18).

        Manually run and inspect specific problems.
        """
        problems = self.metadata_store.get_by_difficulty(difficulty)
        if not problems:
            print(f"No problems found for difficulty: {difficulty}")
            return

        selected = problems[:count]
        print(f"\nValidating {len(selected)} {difficulty} problems:\n")

        for meta in selected:
            print(f"Problem: {meta.problem_name}")
            print(f"  Generated plan length: {meta.plan_length}")
            print(f"  Baseline planner time: {meta.planner_time:.2f}s")
            print(f"  Plan cost: {meta.plan_cost}")
            print(f"  Nodes expanded: {meta.nodes_expanded}")
            print()

    def print_summary(self) -> None:
        """Print summary statistics."""
        stats = self.metadata_store.get_summary_stats()

        print(f"\n{'=' * 70}")
        print("SUMMARY STATISTICS")
        print(f"{'=' * 70}\n")

        for difficulty in ['small', 'medium', 'large']:
            if difficulty in stats:
                s = stats[difficulty]
                print(f"{difficulty.upper()}:")
                print(f"  Count: {s['count']}")
                print(f"  Successful: {s['successful']}")
                if s['avg_time']:
                    print(f"  Avg time: {s['avg_time']:.2f}s")
                    print(f"  Min time: {s['min_time']:.2f}s")
                    print(f"  Max time: {s['max_time']:.2f}s")
                print()

    def calibrate_difficulty(self) -> None:
        """
        Recommend difficulty tier adjustments (Requirement #17).

        Analyze baseline planner results and suggest parameter changes.
        """
        stats = self.metadata_store.get_summary_stats()

        print(f"\n{'=' * 70}")
        print("DIFFICULTY CALIBRATION RECOMMENDATIONS")
        print(f"{'=' * 70}\n")

        target_times = {'small': 1, 'medium': 180, 'large': 420}  # seconds

        for difficulty in ['small', 'medium', 'large']:
            if difficulty not in stats:
                print(f"{difficulty.upper()}: No data")
                continue

            s = stats[difficulty]
            avg_time = s['avg_time'] or 0
            target_time = target_times[difficulty]

            tier = DIFFICULTY_TIERS[difficulty]
            print(f"{difficulty.upper()}:")
            print(f"  Current target plan length: {tier.target_length}")
            print(f"  Average solve time: {avg_time:.2f}s (target: {target_time}s)")

            if avg_time > target_time * 1.5:
                suggested = max(tier.target_length - 2, 3)
                print(f"  → Problems too hard; reduce plan length to ~{suggested}")
            elif avg_time < target_time * 0.5:
                suggested = tier.target_length + 3
                print(f"  → Problems too easy; increase plan length to ~{suggested}")
            else:
                print(f"  → OK, keep as is")
            print()





def main():
    """Main CLI entry point."""
    parser = argparse.ArgumentParser(
        description="Blocksworld PDDL Problem Generation Framework"
    )

    subparsers = parser.add_subparsers(dest='command', help='Commands')

    # Generate command
    gen_parser = subparsers.add_parser('generate', help='Generate problems')
    gen_parser.add_argument(
        '--num-problems',
        type=int,
        default=10,
        help='Number of problems to generate'
    )
    gen_parser.add_argument(
        '--difficulty',
        choices=['small', 'medium', 'large'],
        required=True,
        help='Difficulty tier'
    )
    gen_parser.add_argument(
        '--num-blocks',
        type=int,
        default=4,
        help='Number of blocks per problem'
    )
    gen_parser.add_argument(
        '--seed',
        type=int,
        default=None,
        help='Random seed for reproducibility'
    )
    gen_parser.add_argument(
        '--skip-planner',
        action='store_true',
        help='Skip baseline planner (useful if Fast Downward not installed)'
    )

    gen_parser.add_argument(
        '--timeout',
        type=int,
        default=BASELINE_PLANNER_CONFIG['timeout'],
        help='Max planner time in seconds per problem (default: 600)'
    )

    # Validate subset command
    val_parser = subparsers.add_parser('validate-subset', help='Validate a subset of problems')
    val_parser.add_argument(
        '--difficulty',
        choices=['small', 'medium', 'large'],
        required=True,
        help='Difficulty tier'
    )
    val_parser.add_argument(
        '--count',
        type=int,
        default=5,
        help='Number of problems to validate'
    )

    # NEW: Generate by time command
    time_parser = subparsers.add_parser(
        'generate-by-time',
        help='Generate problems targeting specific solving time'
    )
    time_parser.add_argument(
        '--difficulty',
        choices=['small', 'medium', 'large'],
        required=True,
        help='Difficulty tier'
    )
    time_parser.add_argument(
        '--count',
        type=int,
        default=20,
        help='Number of problems to generate (default: 20)'
    )
    time_parser.add_argument(
        '--seed',
        type=int,
        default=None,
        help='Random seed for reproducibility'
    )

    # Summary command
    subparsers.add_parser('summary', help='Print summary statistics')

    # Calibrate command
    subparsers.add_parser('calibrate', help='Calibrate difficulty tiers')

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        return

    # Initialize framework
    framework = ProblemGenerationFramework(random_seed=args.seed)

    # Execute command
    if args.command == 'generate':
        print(f"Timeout per problem: {args.timeout}s")  # ✓ Show what we're using

        framework.generate_batch(
            num_problems=args.num_problems,
            difficulty=args.difficulty,
            num_blocks=args.num_blocks,
            skip_planner=args.skip_planner,  # NEW
            timeout=args.timeout  # <-- ADD THIS LINE
        )
        framework.print_summary()

    # NEW: Time-based generation command
    elif args.command == 'generate-by-time':
        from time_based_generator import TimeBasedProblemGenerator

        generator = TimeBasedProblemGenerator(
            difficulty=args.difficulty,
            domain_dir=DOMAIN_DIR,
            problems_dir=PROBLEMS_DIR,
            metadata_dir=METADATA_DIR,
            random_seed=args.seed
        )

        # Calibration phase
        if generator.calibrate():
            # Generation phase
            generator.generate_batch(target_count=args.count)

            # Summary
            framework.print_summary()
        else:
            print("✗ Calibration failed. Adjust TIME_DIFFICULTY_TIERS in config.py")
            sys.exit(1)

    elif args.command == 'validate-subset':
        framework.validate_subset(
            difficulty=args.difficulty,
            count=args.count
        )

    elif args.command == 'summary':
        framework.print_summary()

    elif args.command == 'calibrate':
        framework.calibrate_difficulty()


if __name__ == '__main__':
    main()

--------------------------------------------------------------------------------

The file __init__.py code is this:
"""
Blocksworld PDDL Problem Generation Framework

A modular framework for generating diverse, structurally complex Blocksworld
problems for training GNN-based planners.
"""

__version__ = "1.0.0"

from .state import BlocksWorldState, create_empty_state
from .actions import Action, ActionType, ActionExecutor
from .goal_archetypes import GoalArchetype, GoalArchetypeGenerator
from .backward_generator import BackwardProblemGenerator
from .pddl_writer import PDDLWriter
from .baseline_planner import FastDownwardRunner
from .metadata_store import MetadataStore, ProblemMetadata
from .validator import PDDLValidator
from .main import ProblemGenerationFramework

__all__ = [
    'BlocksWorldState',
    'create_empty_state',
    'Action',
    'ActionType',
    'ActionExecutor',
    'GoalArchetype',
    'GoalArchetypeGenerator',
    'BackwardProblemGenerator',
    'PDDLWriter',
    'FastDownwardRunner',
    'MetadataStore',
    'ProblemMetadata',
    'PDDLValidator',
    'ProblemGenerationFramework',
]

--------------------------------------------------------------------------------

The file example_usage.py code is this:
"""
CORRECTED Example usage of the Blocksworld problem generation framework.

This example demonstrates:
1. Creating states manually
2. Applying forward actions correctly
3. Generating diverse problems with different initial and goal states
4. Writing valid PDDL files

Key fixes:
- Proper state validation for held blocks
- Forward search from initial state to reach goal
- Verification that initial ≠ goal
"""

from state import create_empty_state
from actions import Action, ActionType, ActionExecutor
from backward_generator import BackwardProblemGenerator
from pddl_writer import PDDLWriter
from goal_archetypes import GoalArchetype


def example_1_simple_forward_search():
    """
    Example 1: Forward search - the CORRECT way to generate problems.

    This creates an initial state, applies actions, and reaches a goal state.
    Both states are different and the plan is guaranteed to work.
    """
    print("=" * 80)
    print("EXAMPLE 1: Forward Search Problem Generation (CORRECT METHOD)")
    print("=" * 80)

    # Step 1: Create initial state (all blocks on table)
    blocks = ["b0", "b1", "b2", "b3"]
    initial_state = create_empty_state(blocks)

    print("\n[INITIAL STATE]")
    print(f"  {initial_state}")

    # Step 2: Define a sequence of actions to reach goal
    plan = [
        Action(ActionType.PICKUP, ["b0"]),
        Action(ActionType.STACK, ["b0", "b1"]),
        Action(ActionType.PICKUP, ["b2"]),
        Action(ActionType.STACK, ["b2", "b3"]),
        Action(ActionType.UNSTACK, ["b0", "b1"]),
        Action(ActionType.PUTDOWN, ["b0"]),
    ]

    print("\n[EXECUTING PLAN]")
    current_state = initial_state.copy()

    for i, action in enumerate(plan, 1):
        result = ActionExecutor.execute_forward(current_state, action)
        if result is None:
            print(f"  {i}. {action} ✗ FAILED (preconditions not met)")
            break
        current_state = result
        print(f"  {i}. {action} ✓")

    goal_state = current_state

    # Step 3: Verify states are different
    print("\n[VERIFICATION]")
    print(f"  Initial state == Goal state? {initial_state == goal_state}")
    if initial_state != goal_state:
        print(f"  ✓ SUCCESS: States are DIFFERENT")
    else:
        print(f"  ✗ ERROR: States are identical!")
        return

    print(f"\n[FINAL STATES]")
    print(f"  Initial: {initial_state}")
    print(f"  Goal:    {goal_state}")
    print(f"  Plan length: {len(plan)}")

    # Step 4: Write PDDL files
    print(f"\n[GENERATING PDDL FILES]")
    pddl_writer = PDDLWriter()
    pddl_writer.write_domain("example1_domain.pddl")
    pddl_writer.write_problem(
        "example1_problem.pddl",
        "example1",
        initial_state,
        goal_state
    )
    print(f"  ✓ Written: example1_domain.pddl")
    print(f"  ✓ Written: example1_problem.pddl")

    # Print the generated PDDL
    print(f"\n[GENERATED PDDL PROBLEM]")
    with open("../example1_problem.pddl", 'r') as f:
        print(f.read())


def example_2_fixed_backward_generator():
    """
    Example 2: Using the FIXED backward generator.

    The backward generator now works correctly because the state validation
    has been fixed to handle held blocks properly.
    """
    print("\n" + "=" * 80)
    print("EXAMPLE 2: Backward Generator (Now Fixed!)")
    print("=" * 80)

    generator = BackwardProblemGenerator(random_seed=42)

    print("\n[GENERATING PROBLEM]")
    print("  Blocks: 5")
    print("  Target plan length: 8")
    print("  Goal archetype: SINGLE_TOWER")

    try:
        initial_state, goal_state, plan, archetype = generator.generate_problem(
            num_blocks=5,
            target_plan_length=8,
            archetype=GoalArchetype.SINGLE_TOWER,
            tolerance=2
        )

        print(f"\n[RESULT]")
        print(f"  Archetype: {archetype.value}")
        print(f"  Plan length: {len(plan)}")
        print(f"  Blocks: {sorted(initial_state.blocks)}")

        # Verify different
        print(f"\n[VERIFICATION]")
        print(f"  Initial == Goal? {initial_state == goal_state}")

        if initial_state == goal_state:
            print(f"  ✗ ERROR: States are identical!")
            return

        print(f"  ✓ States are DIFFERENT")

        # Verify plan works
        test_state = initial_state.copy()
        for action in plan:
            test_state = ActionExecutor.execute_forward(test_state, action)
            if test_state is None:
                print(f"  ✗ Plan validation FAILED")
                return

        if test_state == goal_state:
            print(f"  ✓ Plan successfully reaches goal")
        else:
            print(f"  ✗ Plan does not reach goal")
            return

        print(f"\n[INITIAL STATE]")
        print(f"  {initial_state}")

        print(f"\n[GOAL STATE]")
        print(f"  {goal_state}")

        print(f"\n[PLAN ({len(plan)} steps)]")
        for i, action in enumerate(plan, 1):
            print(f"  {i}. {action}")

        # Generate PDDL
        pddl_writer = PDDLWriter()
        pddl_writer.write_domain("example2_domain.pddl")
        pddl_writer.write_problem(
            "example2_problem.pddl",
            "example2",
            initial_state,
            goal_state
        )
        print(f"\n[PDDL FILES]")
        print(f"  ✓ Written: example2_domain.pddl")
        print(f"  ✓ Written: example2_problem.pddl")

    except Exception as e:
        print(f"  ✗ Error: {e}")
        import traceback
        traceback.print_exc()


def example_3_all_archetypes():
    """
    Example 3: Generate problems with different goal archetypes.

    Shows the variety of problems that can be generated.
    """
    print("\n" + "=" * 80)
    print("EXAMPLE 3: All Goal Archetypes")
    print("=" * 80)

    generator = BackwardProblemGenerator(random_seed=123)

    for archetype in [
        GoalArchetype.SINGLE_TOWER,
        GoalArchetype.MULTIPLE_TOWERS,
        GoalArchetype.CLEAR_TABLE,
        GoalArchetype.SCATTERED_RELATIONS,
        GoalArchetype.MIXED_PYRAMID,
    ]:
        print(f"\n[{archetype.value.upper()}]")
        try:
            initial_state, goal_state, plan, _ = generator.generate_problem(
                num_blocks=4,
                target_plan_length=6,
                archetype=archetype,
                tolerance=1
            )

            is_different = initial_state != goal_state
            print(f"  Plan length: {len(plan)}")
            print(f"  Different states: {'✓ YES' if is_different else '✗ NO'}")

            if not is_different:
                print(f"    WARNING: Initial and goal states are identical!")

        except Exception as e:
            print(f"  ✗ Error: {e}")


def example_4_batch_generation():
    """
    Example 4: Generate a batch of diverse problems.

    Creates multiple problems with different seeds.
    """
    print("\n" + "=" * 80)
    print("EXAMPLE 4: Batch Generation (10 problems)")
    print("=" * 80)

    num_problems = 10
    problems = []

    for i in range(num_problems):
        generator = BackwardProblemGenerator(random_seed=i)
        try:
            initial_state, goal_state, plan, archetype = generator.generate_problem(
                num_blocks=4,
                target_plan_length=7,
                tolerance=2
            )

            is_different = initial_state != goal_state
            problems.append({
                'id': i,
                'archetype': archetype.value,
                'plan_length': len(plan),
                'different': is_different,
                'initial': initial_state,
                'goal': goal_state,
                'plan': plan
            })

            status = "✓" if is_different else "✗"
            print(f"  Problem {i}: {status} {archetype.value:20s} length={len(plan)}")

        except Exception as e:
            print(f"  Problem {i}: ✗ Error: {e}")

    # Summary
    print(f"\n[SUMMARY]")
    successful = sum(1 for p in problems if p['different'])
    print(f"  Generated: {len(problems)}/{num_problems}")
    print(f"  With different states: {successful}/{len(problems)}")

    if successful == len(problems):
        print(f"  ✓ ALL PROBLEMS VALID")
    else:
        print(f"  ✗ Some problems have identical initial/goal states")

    # Write first 3 to PDDL
    print(f"\n[WRITING FIRST 3 PROBLEMS TO PDDL]")
    pddl_writer = PDDLWriter()
    pddl_writer.write_domain("batch_domain.pddl")

    for problem in problems[:3]:
        pddl_writer.write_problem(
            f"batch_problem_{problem['id']}.pddl",
            f"batch-problem-{problem['id']}",
            problem['initial'],
            problem['goal']
        )
        print(f"  ✓ Written: batch_problem_{problem['id']}.pddl")


def example_5_state_transitions_visualization():
    """
    Example 5: Visualize state transitions during forward search.

    Shows how each action transforms the state.
    """
    print("\n" + "=" * 80)
    print("EXAMPLE 5: State Transitions Visualization")
    print("=" * 80)

    blocks = ["b0", "b1", "b2"]
    state = create_empty_state(blocks)

    print(f"\nStep 0: Initial State")
    print(f"  on_table: {state.on_table}")
    print(f"  on: {state.on}")
    print(f"  clear: {state.clear}")
    print(f"  holding: {state.holding}")
    print(f"  arm_empty: {state.arm_empty}")

    actions = [
        ("pickup", Action(ActionType.PICKUP, ["b0"])),
        ("stack(b0, b1)", Action(ActionType.STACK, ["b0", "b1"])),
        ("pickup", Action(ActionType.PICKUP, ["b2"])),
        ("stack(b2, b0)", Action(ActionType.STACK, ["b2", "b0"])),
    ]

    for step, (label, action) in enumerate(actions, 1):
        state = ActionExecutor.execute_forward(state, action)
        if state is None:
            print(f"✗ Action failed!")
            break

        print(f"\nStep {step}: {label}")
        print(f"  on_table: {state.on_table}")
        print(f"  on: {state.on}")
        print(f"  clear: {state.clear}")
        print(f"  holding: {state.holding}")
        print(f"  arm_empty: {state.arm_empty}")


if __name__ == "__main__":
    example_1_simple_forward_search()
    example_2_fixed_backward_generator()
    example_3_all_archetypes()
    example_4_batch_generation()
    example_5_state_transitions_visualization()

    print("\n" + "=" * 80)
    print("✓ ALL EXAMPLES COMPLETED SUCCESSFULLY!")
    print("=" * 80)

--------------------------------------------------------------------------------

